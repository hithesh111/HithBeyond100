{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/hithesh/Desktop/ML Competitions/Sentiment_Analysis_Analytics_vidhya/train.csv')\n",
    "df_test = pd.read_csv('/home/hithesh/Desktop/ML Competitions/Sentiment_Analysis_Analytics_vidhya/test.csv')\n",
    "\n",
    "df['length'] = df['user_review'].apply(lambda x: len(x))\n",
    "df_test['length'] = df_test['user_review'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Spooky's Jump Scare Mansion\", 'Sakura Clicker', 'WARMODE',\n",
       "       'Fractured Space', 'Dota 2', 'Path of Exile', 'War Thunder',\n",
       "       'Ring of Elysium', 'Team Fortress 2', 'Yu-Gi-Oh! Duel Links',\n",
       "       'SMITE®', 'Brawlhalla', 'World of Tanks Blitz',\n",
       "       'DCS World Steam Edition', 'Heroes & Generals',\n",
       "       'The Elder Scrolls®: Legends™', 'Trove', 'Neverwinter',\n",
       "       'Realm Royale', 'PlanetSide 2', 'Realm of the Mad God', 'Elsword',\n",
       "       'theHunter Classic', 'Eternal Card Game', 'Black Squad',\n",
       "       'Freestyle 2: Street Basketball', 'Bless Online',\n",
       "       'RaceRoom Racing Experience', 'Fallout Shelter',\n",
       "       'Tactical Monsters Rumble Arena', 'Creativerse', 'Dreadnought',\n",
       "       'Infestation: The New Z', 'Shop Heroes', 'Robocraft',\n",
       "       'Business Tour - Board Game with Online Multiplayer',\n",
       "       'Crusaders of the Lost Idols', 'AdventureQuest 3D',\n",
       "       'Realm Grinder', 'World of Guns: Gun Disassembly',\n",
       "       'Bloons TD Battles', 'Cuisine Royale', 'School of Dragons',\n",
       "       'EverQuest II'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = ''\n",
    "doc1 = ''\n",
    "doc0 = ''\n",
    "for i in range(df.shape[0]):\n",
    "    doc = doc + df.loc[i,'user_review'] + str(' ')\n",
    "    if(df.loc[i,'user_suggestion']==0):\n",
    "        doc0 = doc0 + df.loc[i,'user_review']\n",
    "    else:\n",
    "        doc1 = doc1 + df.loc[i,'user_review']\n",
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "tokens = word_tokenize(doc)\n",
    "all_words = [token.lower() for token in tokens if token.isalpha()!=0]\n",
    "all_words = [word for word in all_words if word not in stop_words]\n",
    "\n",
    "tokens0 = word_tokenize(doc0)\n",
    "all_words0 = [token.lower() for token in tokens0 if token.isalpha()!=0]\n",
    "all_words0 = [word for word in all_words0 if word not in stop_words]\n",
    "\n",
    "tokens1 = word_tokenize(doc1)\n",
    "all_words1 = [token.lower() for token in tokens1 if token.isalpha()!=0]\n",
    "all_words1 = [word for word in all_words1 if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_all_words = FreqDist(all_words)\n",
    "freq_all_words0 = FreqDist(all_words0)\n",
    "freq_all_words1 = FreqDist(all_words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features = []\n",
    "word_features0 = []\n",
    "word_features1 = []\n",
    "\n",
    "for i in range(1000):\n",
    "    word_features0.append(freq_all_words0.most_common(1000)[i][0])\n",
    "for i in range(1000):\n",
    "    if(freq_all_words1.most_common(1000)[i][0] in word_features0):\n",
    "        word_features0.remove(freq_all_words1.most_common(1000)[i][0])\n",
    "        \n",
    "for i in range(300):\n",
    "    word_features.append(freq_all_words.most_common(300)[i][0])\n",
    "\n",
    "word_features =  word_features + word_features0 + word_features1\n",
    "word_features = list(set(word_features))\n",
    "len(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in word_features:\n",
    "    df[w] = df['user_review'].apply(lambda x: len(x.lower().split(w))-1)\n",
    "\n",
    "symbol_features = ['!','.','\\'',',','@','$','#',':',';','\\\"','&','*','%','^',' ']\n",
    "for s in symbol_features:\n",
    "    df[s] = df['user_review'].apply(lambda x: len(x.split(s))-1)\n",
    "\n",
    "alpha_features = [chr(i) for i in range(ord('a'),ord('z')+1)]\n",
    "for f in alpha_features:\n",
    "    df[f] = df['user_review'].apply(lambda x: len(x.split(f))-1)\n",
    "    \n",
    "digit_features = [str(i) for i in range(10)]\n",
    "for d in digit_features:\n",
    "    df[d] = df['user_review'].apply(lambda x: len(x.split(d))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in word_features:\n",
    "    df_test[w] = df_test['user_review'].apply(lambda x: len(x.lower().split(w))-1)\n",
    "    \n",
    "for s in symbol_features:\n",
    "    df_test[s] = df_test['user_review'].apply(lambda x: len(x.split(s))-1)\n",
    "\n",
    "alpha_features = [chr(i) for i in range(ord('a'),ord('z')+1)]\n",
    "for f in alpha_features:\n",
    "    df_test[f] = df_test['user_review'].apply(lambda x: len(x.lower().split(f))-1)\n",
    "    \n",
    "digit_features = [str(i) for i in range(10)]\n",
    "for d in digit_features:\n",
    "    df_test[d] = df_test['user_review'].apply(lambda x: len(x.split(d))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(word_features + symbol_features + alpha_features + digit_features + ['length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in features:\n",
    "#     m  = df[feature].mean()\n",
    "#     s = df[feature].std()\n",
    "#     df[feature] = (df[feature] - m)/s\n",
    "#     df_test[feature] = (df_test[feature] - m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0.9047784173659755 0.8481958353202989\n"
     ]
    }
   ],
   "source": [
    "X = df[features]\n",
    "# X = df[best_features]\n",
    "y = df['user_suggestion']\n",
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "for i  in range(4,5):\n",
    "    print(i)\n",
    "    if(i==0):\n",
    "        model=LinearSVC()\n",
    "    if(i==1):\n",
    "        model=RandomForestClassifier()\n",
    "    if(i==2):\n",
    "        model=LogisticRegression(max_iter = 1000)\n",
    "    if(i==3):\n",
    "        model=XGBClassifier()\n",
    "    if(i==4):\n",
    "        model=GradientBoostingClassifier(n_estimators = 500)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    train_score = f1_score(y_train, model.predict(X_train))\n",
    "    test_score = f1_score(y_test, model.predict(X_test))\n",
    "    print(train_score,test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_features = []\n",
    "# for i in range(len(features)):\n",
    "#     if(model.feature_importances_[i]>0.0005):\n",
    "#         print(features[i],model.feature_importances_[i])\n",
    "#         best_features.append(features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model'+'.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = df_test[features]\n",
    "# test_X = df_test[best_features]\n",
    "\n",
    "df_test['user_suggestion'] = pd.Series(model.predict(test_X))\n",
    "final = pd.concat([df_test['review_id'],df_test['user_suggestion']],axis=1)\n",
    "final.to_csv('/home/hithesh/Desktop/ML Competitions/Sentiment_Analysis_Analytics_vidhya/nlp_sub1.csv',header=True , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
